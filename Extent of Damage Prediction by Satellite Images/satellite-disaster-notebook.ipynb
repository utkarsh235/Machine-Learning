{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "satellite-disaster-notebook1 (2).ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/utkarsh235/Machine-Learning/blob/master/Extent%20of%20Damage%20Prediction%20by%20Satellite%20Images/satellite-disaster-notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "nZaJm70g6-gq"
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "'''for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))'''\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Cx2_RUQb6-gx"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "from keras.models import Sequential, Model\n",
        "from keras.applications import VGG16, VGG19, Xception, ResNet50, ResNet101, InceptionV3, InceptionResNetV2, MobileNetV2, DenseNet121, DenseNet169\n",
        "from keras.layers import Input, Flatten, Dense, Dropout\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "j16b9fDB6-gz"
      },
      "source": [
        "main_folder = '../input/xview2-damage-assessment'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zI8_rd1b6-g0"
      },
      "source": [
        "train_images = train_folder = main_folder + '/train/images'\n",
        "holdout_folder = main_folder + '/hold'\n",
        "tier3_folder = main_folder + '/tier3'\n",
        "tier3_images = tier3_folder + '/images'\n",
        "holdout_images = holdout_folder+'/images'\n",
        "\n",
        "train_labels_path = main_folder + '/train/labels'\n",
        "hold_labels_path = main_folder + '/hold/labels'\n",
        "tier3_labels_path = main_folder + '/tier3/labels'\n",
        "#train_labels_path = '../input/xview2-damage-assessment/train/labels'\n",
        "#hold_labels_path = '../input/xview2-damage-assessment/hold/labels'\n",
        "#tier3_labels_path = '../input/xview2-damage-assessment/tier3/labels'\n",
        "\n",
        "#train_images = train_folder = '../input/xview2-damage-assessment/train/images'\n",
        "#holdout_folder = '../input/xview2-damage-assessment/hold'\n",
        "#tier3_folder = '../input/xview2-damage-assessment/tier3'\n",
        "#tier3_images = tier3_folder + '/images'\n",
        "print(os.listdir(holdout_folder))\n",
        "print(os.listdir(tier3_folder))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1rHcGIM96-g1"
      },
      "source": [
        "info = pd.DataFrame(\n",
        "    {'Name': '_',\n",
        "     'index': '0',\n",
        "     'pre_path': '',\n",
        "     'post_path': '',\n",
        "     'paths': 'paths'\n",
        "    },index=range(len(os.listdir(train_folder)) + len(os.listdir(holdout_folder+'/images'))+ len(os.listdir(tier3_images)))\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UbwqaZuH6-g3"
      },
      "source": [
        "info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ePNky5r16-g3"
      },
      "source": [
        "print(len(os.listdir(train_images)))\n",
        "print(len(os.listdir(holdout_images)))\n",
        "print(len(os.listdir(tier3_images)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-output": true,
        "trusted": true,
        "id": "071gBX7W6-g4"
      },
      "source": [
        "start = time.time()\n",
        "for i in range(len(os.listdir(train_folder))+ len(os.listdir(holdout_images))+ len(os.listdir(tier3_images))):\n",
        "    if i % 1000 == 0:\n",
        "        print(i)\n",
        "    if i < len(os.listdir(train_folder)):\n",
        "        path = train_folder + '/' + os.listdir(train_folder)[i]\n",
        "        broken = os.listdir(train_folder)[i].split('_')\n",
        "\n",
        "        pre_path = train_folder + '/' + broken[0] + '_' + broken[1] + '_' + 'pre_disaster.png'  \n",
        "        post_path = train_folder + '/' + broken[0] + '_' + broken[1] + '_' + 'post_disaster.png'\n",
        "    elif i > len(os.listdir(train_folder)) and i < (len(info) - len(os.listdir(tier3_images))):\n",
        "        path = holdout_images + '/' + os.listdir(holdout_images)[i-len(os.listdir(train_folder))]\n",
        "        broken = os.listdir(holdout_images)[i-len(os.listdir(train_folder))].split('_')\n",
        "\n",
        "        pre_path = holdout_images + '/' + broken[0] + '_' + broken[1] + '_' + 'pre_disaster.png'  \n",
        "        post_path = holdout_images + '/' + broken[0] + '_' + broken[1] + '_' + 'post_disaster.png'\n",
        "    else:\n",
        "        path = tier3_images + '/' + os.listdir(tier3_images)[i-len(os.listdir(train_folder))-len(os.listdir(holdout_images))]\n",
        "        broken = os.listdir(tier3_images)[i-len(os.listdir(train_folder))-len(os.listdir(holdout_images))].split('_')\n",
        "\n",
        "        pre_path = tier3_images + '/' + broken[0] + '_' + broken[1] + '_' + 'pre_disaster.png'  \n",
        "        post_path = tier3_images + '/' + broken[0] + '_' + broken[1] + '_' + 'post_disaster.png'\n",
        "        \n",
        "        \n",
        "    info['Name'][i] = broken[0] + '_' + broken[1]\n",
        "    info['index'][i] = broken[1]\n",
        "    info['pre_path'][i] = pre_path\n",
        "    info['post_path'][i] = post_path\n",
        "    info['paths'][i] = [pre_path, post_path]\n",
        "end = time.time()\n",
        "print(f'Operation executed in {end-start} seconds')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "g6XH_3S-6-g6"
      },
      "source": [
        "info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "EfWJ57fJ6-g7"
      },
      "source": [
        "info.drop_duplicates(subset='pre_path', keep='first', inplace=True)\n",
        "info.reset_index(inplace=True)\n",
        "info.drop(['level_0'], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SDkXl1nr6-g8"
      },
      "source": [
        "info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "lnT8Qjrd6-g8"
      },
      "source": [
        "print(info['pre_path'][0])\n",
        "print(info['post_path'][0])\n",
        "print(info['paths'][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "e54eoU8u6-g9"
      },
      "source": [
        "start = time.time()\n",
        "info['labels'] = ''\n",
        "info['disaster_type'] = ''\n",
        "for i in range(len(info)):\n",
        "    if i%500 == 0:\n",
        "        print(i)\n",
        "    \n",
        "    if i < len(os.listdir(train_folder))//2:\n",
        "        pass\n",
        "        json_file = train_labels_path + '/' + info['Name'][i] + '_' + 'post_disaster.json'\n",
        "        jso_post = pd.read_json(json_file)\n",
        "        info['disaster_type'][i] =  jso_post['metadata']['disaster_type']\n",
        "        length = len(jso_post.iloc[1,:][0])\n",
        "        #print(jso_post.iloc[1, :][0][0]['properties']['subtype'])\n",
        "        for j in range(length):\n",
        "            info['labels'][i] = info['labels'][i] + jso_post.iloc[1,:][0][j]['properties']['subtype'] + '_'\n",
        "    \n",
        "    elif i > len(os.listdir(train_folder))//2 and i <= ( len(os.listdir(train_folder)) + len(os.listdir(holdout_images)) )//2:\n",
        "        json_file = hold_labels_path + '/' + info['Name'][i] + '_' + 'post_disaster.json'\n",
        "        #print(json_file)\n",
        "        jso_post = pd.read_json(json_file)\n",
        "        info['disaster_type'][i] =  jso_post['metadata']['disaster_type']\n",
        "        length = len(jso_post.iloc[1,:][0])\n",
        "        #print(jso_post.iloc[1, :][0][0]['properties']['subtype'])\n",
        "        for j in range(length):\n",
        "            info['labels'][i] = info['labels'][i] + jso_post.iloc[1,:][0][j]['properties']['subtype'] + '_'\n",
        "    \n",
        "    else:\n",
        "        json_file = tier3_labels_path + '/' + info['Name'][i] + '_' + 'post_disaster.json'\n",
        "        jso_post = pd.read_json(json_file)\n",
        "        info['disaster_type'][i] =  jso_post['metadata']['disaster_type']\n",
        "        length = len(jso_post.iloc[1,:][0])\n",
        "        #print(jso_post.iloc[1, :][0][0]['properties']['subtype'])\n",
        "        for j in range(length):\n",
        "            info['labels'][i] = info['labels'][i] + jso_post.iloc[1,:][0][j]['properties']['subtype'] + '_'\n",
        "        \n",
        "end = time.time()\n",
        "print(end-start)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6EW9YjnV6-hA"
      },
      "source": [
        "info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PKtE8lz26-hB"
      },
      "source": [
        "info['simplified_labels'] = 0\n",
        "for i in range(len(info)):\n",
        "    info['simplified_labels'][i] = info['labels'][i].split('_')\n",
        "    info['simplified_labels'][i] = info['simplified_labels'][i][:-1]\n",
        "    \n",
        "for i in range(len(info)):\n",
        "    if info['simplified_labels'][i] == []:\n",
        "        info['simplified_labels'][i] = ['no-damage']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vgvfsZNP6-hC"
      },
      "source": [
        "info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cE3gmbMZ6-hC"
      },
      "source": [
        "info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MaR77HQB6-hD"
      },
      "source": [
        "info['simplified_labels'].dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "TSyfUwCf6-hE"
      },
      "source": [
        "count = 0\n",
        "for j in range(len(info)):\n",
        "    if info['simplified_labels'][j] == list(['un-classified']):\n",
        "        count+=1\n",
        "count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rxMwxQpE6-hF"
      },
      "source": [
        "count = 0\n",
        "for j in range(len(info)):\n",
        "    if info['simplified_labels'][j] == list([\"no-damage\"]):\n",
        "        count += 1\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yzMQP4oh6-hG"
      },
      "source": [
        "for i in range(10):\n",
        "    pre = info['paths'][i][0]\n",
        "    post = info['paths'][i][1]\n",
        "    pre = cv2.imread(pre)\n",
        "    post = cv2.imread(post)\n",
        "    print(pre.shape, post.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGv7ofpi6-hG"
      },
      "source": [
        "Every pre and post image is of shape (1024 x 1024 x 3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3xUKuKbI6-hH"
      },
      "source": [
        "len(np.where(info['labels'] == '')[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9FnSjneB6-hH"
      },
      "source": [
        "info['disaster_type'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qJn5Ga-C6-hI"
      },
      "source": [
        "info['regression_labels'] = 1.33\n",
        "\n",
        "def counter(lst):\n",
        "    a = Counter(lst)\n",
        "    num_no_damage = a['no-damage']\n",
        "    num_minor_damage = a['minor-damage']\n",
        "    num_major_damage = a['major-damage']\n",
        "    num_destroyed = a['destroyed']\n",
        "    num_unclassified = a['un-classified']\n",
        "    return num_no_damage, num_minor_damage, num_major_damage, num_destroyed, num_unclassified\n",
        "\n",
        "for i in range(len(info)):\n",
        "    num_no_damage, num_minor_damage, num_major_damage, num_destroyed, num_unclassified = counter(info['simplified_labels'][i])\n",
        "    reg_value = ( (num_no_damage*0)+(num_minor_damage*0.33)+(num_major_damage*0.66)+(num_destroyed*1)+(num_unclassified*0.50) ) / len(info['simplified_labels'][i]) \n",
        "    info['regression_labels'][i] = reg_value       \n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DCn3UZWF6-hI"
      },
      "source": [
        "\n",
        "info['regression_labels'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KKPWrVn06-hJ"
      },
      "source": [
        "info['regression_labels_str'] = str(info['regression_labels'])\n",
        "for i in range(len(info)):\n",
        "    info['regression_labels_str'][i] = str(info['regression_labels'][i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "dC9uOZKx6-hJ"
      },
      "source": [
        "for i in range(len(info)):\n",
        "    info['regression_labels'][i] = float(info['regression_labels_str'][i][0:4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MGEHZ5SE6-hK"
      },
      "source": [
        "info_copied = info.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xjFs82G76-hK"
      },
      "source": [
        "info_sampled = info_copied.sample(10).reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "axc0bofu6-hL"
      },
      "source": [
        "info_sampled"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "v2pK6Syb6-hM"
      },
      "source": [
        "X = info_copied.drop(['regression_labels'], axis=1)\n",
        "Y = info_copied['regression_labels']\n",
        "train_x, val_x, train_y, val_y = train_test_split(X, Y, shuffle=True, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "igqrNgeU6-hM"
      },
      "source": [
        "batch_size=40\n",
        "#sampled_info = info.sample(batch_size).reset_index()\n",
        "def train_generator(sampled_info, batch_size=batch_size):\n",
        "    while True:\n",
        "        batch_train_images = []\n",
        "        batch_train_labels = []\n",
        "        sampled_dataset = sampled_info.sample(batch_size).reset_index()\n",
        "        for i in range(len(sampled_dataset)):\n",
        "            pre_img_path = sampled_dataset['pre_path'][i]\n",
        "            post_img_path = sampled_dataset['post_path'][i]\n",
        "            preprocessed_array = read_and_process_img(pre_img_path, post_img_path)\n",
        "            batch_train_images.append(preprocessed_array)\n",
        "            batch_train_labels.append(sampled_dataset['regression_labels'][i])\n",
        "            #print(i)\n",
        "        \n",
        "        batch_train_images = np.array(batch_train_images)\n",
        "        batch_train_labels = np.array(batch_train_labels)\n",
        "        yield(batch_train_images, batch_train_labels)\n",
        "\n",
        "def read_and_process_img(pre_img_path, post_img_path):\n",
        "    img_size=224\n",
        "    pre_img = cv2.imread(pre_img_path)\n",
        "    post_img = cv2.imread(post_img_path)\n",
        "    pre_img = cv2.resize(pre_img, (img_size, img_size))\n",
        "    post_img = cv2.resize(post_img, (img_size, img_size))\n",
        "    final_array = np.concatenate((pre_img, post_img), axis=2)\n",
        "    final_array = final_array / 255\n",
        "    return final_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "v9s0p65c6-hN"
      },
      "source": [
        "train_x = pd.concat([train_x, train_y], axis=1)\n",
        "val_x = pd.concat([val_x, val_y], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_OBXWLOA6-hO"
      },
      "source": [
        "#trained = train_generator(info)\n",
        "for_train = train_generator(train_x)\n",
        "for_val = train_generator(val_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_kh03nJp6-hP"
      },
      "source": [
        "train_x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YU9vYDwY6-hP"
      },
      "source": [
        "baseModel = tf.keras.applications.Xception(\n",
        "    include_top=False,\n",
        "    weights = None,\n",
        "    #weights=\"imagenet\",\n",
        "    input_tensor=Input(shape=(224, 224, 6)),\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1\n",
        ")\n",
        "#baseModel = VGG16(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
        "headModel = baseModel.output\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(20, activation=\"sigmoid\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(1, activation=\"sigmoid\")(headModel) # Try using sigmoid as well\n",
        "\n",
        "for layer in baseModel.layers:\n",
        "    layer.trainable = False\n",
        "    \n",
        "model = Model(inputs=baseModel.input, outputs=headModel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Vsv9Yv9E6-hQ"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XRzg4e6h6-hQ"
      },
      "source": [
        "model.compile(\n",
        "    optimizer = 'rmsprop',\n",
        "    loss = 'mean_squared_error',\n",
        "    metrics = ['accuracy', 'mse']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KXZ4OfFz6-hR"
      },
      "source": [
        "history = model.fit(for_train, steps_per_epoch=len(train_x)//batch_size, epochs=5, validation_data=for_val, validation_steps=len(val_x)//batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "G7lPuUZ96-hR"
      },
      "source": [
        "output_result_path = './'\n",
        "hist_df = pd.DataFrame(history.history) \n",
        "\n",
        "# or save to csv: \n",
        "hist_csv_file = output_result_path + 'history.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "4dYLl-ta6-hS"
      },
      "source": [
        "# Insert Output Path Below\n",
        "output_path = './'\n",
        "tf.keras.models.save_model(model, output_path+'model_xception.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zy7GAFXA6-hS"
      },
      "source": [
        "img_size = 224\n",
        "some_images = []\n",
        "some_labels = []\n",
        "for i in range(200):\n",
        "    pre_img = info['pre_path'][i]\n",
        "    post_img = info['post_path'][i]\n",
        "    pre = cv2.imread(pre_img)\n",
        "    post = cv2.imread(post_img)\n",
        "    pre = cv2.resize(pre, (img_size,img_size))\n",
        "    post = cv2.resize(post, (img_size,img_size))\n",
        "    final = np.concatenate((post, pre), axis=2)\n",
        "    final = final/255\n",
        "    some_images.append(final)\n",
        "    some_labels.append(info['regression_labels'][i])\n",
        "some_images = np.array(some_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "c-ciT-fy6-hT"
      },
      "source": [
        "pred = model.predict(some_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2PsS-iHy6-hT"
      },
      "source": [
        "pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7zQZgwBk6-hU"
      },
      "source": [
        "some_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8V_ReBt26-hU"
      },
      "source": [
        "info_copied['regression_labels'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "nsIL0cD-6-hV"
      },
      "source": [
        "model.evaluate(some_images, np.array(some_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWXZ0TT76-hV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}